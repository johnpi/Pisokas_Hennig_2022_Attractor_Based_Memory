{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6378734-9ce4-46c5-b81c-fc2ebb8fd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine multiple dicts into one\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import numbers\n",
    "\n",
    "def compare(a, b):\n",
    "    \"\"\" Compare if two variables have equal values, it can compare only \n",
    "        numbers, lists, and numpy arrays. Everythings else will return False. \"\"\"\n",
    "    if isinstance(a, numbers.Number) and isinstance(b, numbers.Number):\n",
    "        return a == b\n",
    "    elif isinstance(a, dict) and isinstance(b, dict):\n",
    "        return a == b\n",
    "    elif isinstance(a, list) and isinstance(b, list):\n",
    "        return (np.array(a) == np.array(b)).all()\n",
    "    elif isinstance(a, np.ndarray) and isinstance(b, np.ndarray):\n",
    "        return np.array_equal(a, b)\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def merge_dicts(a, b, path=None, bail_on_conflict=True):\n",
    "    \"\"\" Merges two nested dictionaries. \n",
    "        b is merged into a, altering a and returning it.\n",
    "        Usage: d = merge_dicts(a, b) \n",
    "        Reports error if there is conflict.\n",
    "        a, b : the two dictionaries to merge\n",
    "        path : Used internally to keep track of the nested dict keys path for reporting errors\n",
    "        bail_on_conflict : What to do if a conflict is found, \n",
    "                           True throws Exception, \n",
    "                           False keeps the value of dictionary a \"\"\"\n",
    "    if path is None: path = [] # Keep track of the nested dict keys path for reporting errors\n",
    "    for key in b:\n",
    "        if key in a:\n",
    "            if isinstance(a[key], dict) and isinstance(b[key], dict):\n",
    "                merge_dicts(a[key], b[key], path + [str(key)], bail_on_conflict)\n",
    "            #elif a[key] == b[key]:\n",
    "            elif compare(a[key], b[key]):\n",
    "                pass # same leaf value\n",
    "            else:\n",
    "                if bail_on_conflict:\n",
    "                    raise Exception('Conflict at %s' % '.'.join(path + [str(key)]))\n",
    "                else:\n",
    "                    print('Conflict at {}, {}.'.format('.'.join(path + [str(key)]), 'kept value from dictionary \\'a\\''))\n",
    "        else:\n",
    "            a[key] = b[key]\n",
    "    return a\n",
    "\n",
    "# Example\n",
    "# a = {'a': {'1': 1, '2': 2}, 'b': {'11': 1, '12': 2}}\n",
    "# b = {'c': {'21': 1, '22': 2}, 'd': {'31': 1, '32': 2}}\n",
    "# c = {'c': {'21': 41, '42': 42}}\n",
    "# d = merge_dicts(deepcopy(a), b)\n",
    "# e = merge_dicts(d, c, bail_on_conflict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198403b2-0ea5-4077-b37c-1c09bf191d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data (search_dispersion_list dict) from previous run and new additional runs\n",
    "filename_path      = 'data/3_parameters_results_correct_Nl_range_combined_01Ded2022/' # The path\n",
    "input_filename_path      = filename_path + 'individual/' # The path\n",
    "# The data collected on 19 November 2022\n",
    "filename_results_npz_1 = input_filename_path + 'path_analysis_calculation_results_3parameters.npz'\n",
    "# The additional data collected on 1 December 2022\n",
    "filenames_results_npz = ['path_analysis_calculation_results_3parameters_new_batch_0.0.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_0.001.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_0.002.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_0.003.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_0.004.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_0.005.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_0.006.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_0.007.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_0.008.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_0.009.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_0.01.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_0.015.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_0.02.npz', \n",
    "                         # Additional nosie values\n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_noise0.0055_0.0065.npz', \n",
    "                         # Partial extra parameter values not good match to ant data\n",
    "                         #'path_analysis_calculation_results_3parameters_new_batch-Nl0.023r-0.019.npz' # Nl=0.023 r=-0.019\n",
    "                        ]\n",
    "\n",
    "# Save the combined data in\n",
    "output_results_filename_npz = filename_path + 'path_analysis_calculation_results_3parameters.npz'\n",
    "\n",
    "# Load the data of the previous run\n",
    "search_dispersion_dict_1 = np.load(filename_results_npz_1, allow_pickle=True)['arr_0'][()]\n",
    "\n",
    "# Make a copy\n",
    "merged_dict = deepcopy(search_dispersion_dict_1)\n",
    "\n",
    "# Add to the dictionary the entries from the new runs\n",
    "for filename in filenames_results_npz:\n",
    "    search_dispersion_dict_2 = np.load(input_filename_path + filename, allow_pickle=True)['arr_0'][()]\n",
    "    merged_dict = merge_dicts(merged_dict, search_dispersion_dict_2, bail_on_conflict=True)\n",
    "\n",
    "# Store data to file\n",
    "# Store the results_dict dict which contains the calculated path statistics\n",
    "# The data in this file will have the structure dict[wait_noise_sd_str][mem_Nl_str][mem_r_str][measure] = [list of values]\n",
    "np.savez(output_results_filename_npz, merged_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "736f616f-d3b6-4020-82b9-6b00fb797d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the data (search_dispersion_list dict) from previous run and new additional runs\n",
    "filename_path      = 'data/3_parameters_results_extra_search_space_05Ded2022/' # The path\n",
    "input_filename_path      = filename_path + 'individual/' # The path\n",
    "# The data collected on 19 November 2022\n",
    "filename_results_npz_1 = input_filename_path + 'path_analysis_calculation_results_3parameters.npz'\n",
    "# The additional data collected on 1 December 2022\n",
    "filenames_results_npz = ['path_analysis_calculation_results_3parameters_new_batch_extra2.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_extra3.npz', \n",
    "                         'path_analysis_calculation_results_3parameters_new_batch_noise0.0055_0.0065_0.0075.npz'\n",
    "                        ]\n",
    "\n",
    "# Save the combined data in\n",
    "output_results_filename_npz = filename_path + 'path_analysis_calculation_results_3parameters.npz'\n",
    "\n",
    "# Load the data of the previous run\n",
    "search_dispersion_dict_1 = np.load(filename_results_npz_1, allow_pickle=True)['arr_0'][()]\n",
    "\n",
    "# Make a copy\n",
    "merged_dict = deepcopy(search_dispersion_dict_1)\n",
    "\n",
    "# Add to the dictionary the entries from the new runs\n",
    "for filename in filenames_results_npz:\n",
    "    search_dispersion_dict_2 = np.load(input_filename_path + filename, allow_pickle=True)['arr_0'][()]\n",
    "    merged_dict = merge_dicts(merged_dict, search_dispersion_dict_2, bail_on_conflict=True)\n",
    "\n",
    "# Store data to file\n",
    "# Store the results_dict dict which contains the calculated path statistics\n",
    "# The data in this file will have the structure dict[wait_noise_sd_str][mem_Nl_str][mem_r_str][measure] = [list of values]\n",
    "np.savez(output_results_filename_npz, merged_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "763c8cab-4917-46bd-901d-33de77e7294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data (search_dispersion_list dict) from individual files and combine them in a file\n",
    "filename_path      = 'data/3_parameters_results_correct_Nl_range_combined_01Ded2022/' # The path\n",
    "input_filename_path      = filename_path + 'individual/' # The subdir\n",
    "\n",
    "# The data collected on 1 December 2022\n",
    "input_filenames_results_npz = ['path_analysis_calculation_results_3parameters_distance_scaling_factor2.87_noise0.0--0.004.npz', \n",
    "                               'path_analysis_calculation_results_3parameters_distance_scaling_factor2.87_noise0.005--0.007.npz', \n",
    "                               'path_analysis_calculation_results_3parameters_distance_scaling_factor2.87_noise0.008--0.02.npz']\n",
    "\n",
    "# Save the dictionary with the combined data in\n",
    "output_results_filename_npz = filename_path + 'path_analysis_calculation_results_3parameters.npz'\n",
    "\n",
    "# Resulting dictionary\n",
    "merged_dict = {}\n",
    "\n",
    "# Add to the dictionary the entries from the individual files\n",
    "for filename in input_filenames_results_npz:\n",
    "    dict_i = deepcopy(np.load(input_filename_path + filename, allow_pickle=True)['arr_0'][()])\n",
    "    merged_dict = merge_dicts(merged_dict, dict_i, bail_on_conflict=True)\n",
    "\n",
    "# Store data to file\n",
    "# Store the results_dict dict which contains the calculated path statistics\n",
    "# The data in this file will have the structure dict[wait_noise_sd_str][mem_Nl_str][mem_r_str][measure] = [list of values]\n",
    "np.savez(output_results_filename_npz, merged_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d5f4471-0c0d-44d1-ab7d-85afa69b5b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0.0', '0.001', '0.01', '0.016', '0.018', '0.019', '0.02', '0.021', '0.022', '0.023', '0.024', '0.025', '0.03', '0.04', '0.05', '0.06', '0.08', '0.1', '0.12', '0.14', '0.16', '0.18', '0.2', '0.3', '0.5', '0.999', '1.3'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dict['0.0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce28771e-6d52-44fa-9f74-23e83aaf4f61",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'0.005'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmerged_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0.002\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0.005\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()\n",
      "\u001b[0;31mKeyError\u001b[0m: '0.005'"
     ]
    }
   ],
   "source": [
    "merged_dict['0.002']['0.005'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f1ee296-72c8-4f5f-9116-df41e82d5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stored file\n",
    "#filename_path      = 'data/3_parameters_results/'\n",
    "#output_results_filename_npz = filename_path + 'path_analysis_calculation_results_3parameters.npz'\n",
    "#merged_dict = np.load(output_results_filename_npz, allow_pickle=True)['arr_0'][()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4e08dd-e27d-4c32-a992-99893a8c0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dict for existence of values\n",
    "\n",
    "#for wait in ['0.0', '1.0', '24.0', '48.0', '96.0', '144.0', '192.0', '240.0', '288.0', '336.0', '384.0', '432.0']: # 12\n",
    "#    if not wait in merged_dict:\n",
    "#        print('WARNING: key {} not in dictionary merged_dict'.format(wait))\n",
    "for noise in ['0.0', '0.001', '0.002', '0.003', '0.004', '0.005', '0.0055', '0.006', '0.0065', '0.007', '0.008', '0.009', '0.01', '0.015', '0.02']: # 13\n",
    "    if not noise in merged_dict:\n",
    "        print('WARNING: key noise={} not in dictionary merged_dict'.format(noise))\n",
    "    else:\n",
    "        for mem_Nl in ['0.0', '0.001', '0.01', '0.016', '0.018', '0.019', '0.02', '0.021', '0.022', '0.025', '0.03', '0.04', '0.05', '0.06', '0.08', '0.1', '0.12', '0.14', '0.16', '0.18', '0.2', '0.3', '0.5', '0.999', '1.3']: # 25\n",
    "        #for mem_Nl in ['0.0', '0.0005', '0.00075', '0.001', '0.00125', '0.0015', '0.002', '0.0025', '0.003', '0.0035', '0.004', '0.0045', '0.005', '0.0055', '0.006', '0.0065', '0.007', '0.0075', '0.008', '0.0085', '0.009', '0.0095', '0.01']:\n",
    "            if not mem_Nl in merged_dict[noise]:\n",
    "                print('WARNING: key mem_Nl={} not in dictionary merged_dict[{}]'.format(mem_Nl, noise))\n",
    "            else:\n",
    "                for mem_r in ['-0.008', '-0.01', '-0.012', '-0.014', '-0.015', '-0.016', '-0.017', '-0.018', '-0.019', '-0.02', '-0.021', '-0.022', '-0.023', '-0.024', '-0.025', '-0.026', '-0.027', '-0.028', '-0.029', '-0.03', '-0.031', '-0.032', '-0.035', '-0.04', '-0.045', '-0.05', '-0.1']: # 27\n",
    "                #for mem_r in ['-0.033', '-0.034', '-0.035', '-0.036', '-0.037', '-0.038', '-0.039', '-0.04', '-0.041', '-0.042']:\n",
    "                    if not mem_r in merged_dict[noise][mem_Nl]:\n",
    "                        print('WARNING: mem_r=key {} not in dictionary merged_dict[{}][{}]'.format(mem_r, noise, mem_Nl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d858e405-b372-45e7-940d-bce90f5803d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the missing data for an r with Nl=0\n",
    "# We consider merged_dict['0.0']['0.0']['-0.008'] is holding the archetypical value for the Nl=0 condition\n",
    "mem_Nl = '0.0'\n",
    "for noise in ['0.0', '0.001', '0.002', '0.003', '0.004', '0.005', '0.0055', '0.006', '0.0065', '0.007', '0.008', '0.009', '0.01', '0.015', '0.02']: # 13\n",
    "    for mem_r in ['-0.008', '-0.01', '-0.012', '-0.014', '-0.015', '-0.016', '-0.017', '-0.018', '-0.019', '-0.02', '-0.021', '-0.022', '-0.023', '-0.024', '-0.025', '-0.026', '-0.027', '-0.028', '-0.029', '-0.03', '-0.031', '-0.032', '-0.035', '-0.04', '-0.045', '-0.05', '-0.1']: # 27\n",
    "        #if not mem_r in merged_dict[noise][mem_Nl]:\n",
    "        #    print('Was missing a value for dictionary merged_dict[{}][{}][{}]'.format(noise, mem_Nl, mem_r))\n",
    "        #    print('Set to the value of merged_dict[{}][0.0][-0.008]'.format(noise))\n",
    "        #    merged_dict[noise][mem_Nl][mem_r] = deepcopy(merged_dict[noise][mem_Nl]['-0.008'])\n",
    "        if mem_r not in merged_dict[noise][mem_Nl]:\n",
    "            merged_dict[noise][mem_Nl][mem_r] = deepcopy(merged_dict[noise][mem_Nl]['-0.008'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65619869-e1e4-4663-92c3-0007625d2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data to file\n",
    "# Store the results_dict dict which contains the calculated path statistics\n",
    "# The data in this file will have the structure dict[wait_noise_sd_str][mem_Nl_str][mem_r_str][measure] = [list of values]\n",
    "np.savez(output_results_filename_npz, merged_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f5add-edfd-4804-9806-cc1f9892013e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d2c0c71-5dcd-40f0-837e-fc91e2880db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "filename_path      = 'data/3_parameters_results_correct_Nl_range_combined_01Ded2022/' # The path\n",
    "\n",
    "f1 = filename_path +  'with_factor_distance_scaling_factor_3/' + 'path_analysis_calculation_results_3parameters.npz'\n",
    "f2 = filename_path + 'with_factor_distance_scaling_factor_2.87/' + 'path_analysis_calculation_results_3parameters_distance_scaling_factor2.87_noise0.0--0.004.npz'\n",
    "\n",
    "d1 = np.load(f1, allow_pickle=True)['arr_0'][()]\n",
    "d2 = np.load(f2, allow_pickle=True)['arr_0'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5271da2-597e-40da-bf48-f26777cc8c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Wait', 'Dispersion', 'Distance_Median', 'Distance_Median_tocntr', 'Distance_Median_toturn', 'Distance_Dispersion', 'Distance_Dispersion_tocntr', 'Distance_Dispersion_toturn', 'Exit_Angle_Median', 'Exit_Angle_Median_Dev', 'Angle_Dispersion', 'Angle_Dispersion_tocntr', 'Angle_Dispersion_toturn', 'Distance_hypot', 'Distance_hypot_tocntr', 'Distance_hypot_toturn', 'Mean_vector_v', 'Mean_vector_v_proj', 'Distance_to_Nest_Dispersion', 'Distance_to_Nest_Dispersion_tocntr', 'Distance_to_Nest_Dispersion_toturn'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1['0.0']['0.0']['-0.008'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c9a5308-3252-49d9-8e53-1a21bf87567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = 'Distance_Dispersion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a361568b-cfc7-4661-964f-245db3e20149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wait:\n",
      "\n",
      "Dispersion:\n",
      "  They differ\n",
      "\n",
      "Distance_Median:\n",
      "  They differ\n",
      "\n",
      "Distance_Median_tocntr:\n",
      "  They differ\n",
      "\n",
      "Distance_Median_toturn:\n",
      "  They differ\n",
      "\n",
      "Distance_Dispersion:\n",
      "  They differ\n",
      "\n",
      "Distance_Dispersion_tocntr:\n",
      "  They differ\n",
      "\n",
      "Distance_Dispersion_toturn:\n",
      "  They differ\n",
      "\n",
      "Exit_Angle_Median:\n",
      "  They differ\n",
      "\n",
      "Exit_Angle_Median_Dev:\n",
      "  They differ\n",
      "\n",
      "Angle_Dispersion:\n",
      "\n",
      "Angle_Dispersion_tocntr:\n",
      "\n",
      "Angle_Dispersion_toturn:\n",
      "  They differ\n",
      "\n",
      "Distance_hypot:\n",
      "  They differ\n",
      "\n",
      "Distance_hypot_tocntr:\n",
      "  They differ\n",
      "\n",
      "Distance_hypot_toturn:\n",
      "  They differ\n",
      "\n",
      "Mean_vector_v:\n",
      "  They differ\n",
      "\n",
      "Mean_vector_v_proj:\n",
      "  They differ\n",
      "\n",
      "Distance_to_Nest_Dispersion:\n",
      "  They differ\n",
      "\n",
      "Distance_to_Nest_Dispersion_tocntr:\n",
      "  They differ\n",
      "\n",
      "Distance_to_Nest_Dispersion_toturn:\n",
      "  They differ\n"
     ]
    }
   ],
   "source": [
    "from deepdiff import DeepDiff\n",
    "for measure in d1['0.0']['0.0']['-0.008'].keys():\n",
    "    print()\n",
    "    print(measure + ':')\n",
    "    ddiff = DeepDiff(d1['0.0']['0.0']['-0.008'][measure], d2['0.0']['0.0']['-0.008'][measure], significant_digits=2)\n",
    "    #print(ddiff)\n",
    "    if ddiff != {}:\n",
    "        print('  They differ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa8a739d-cce2-4ca3-8925-7748d7b5bde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.225390515729885,\n",
       " 12.959980994941095,\n",
       " 12.935616917340298,\n",
       " 13.50332058085987,\n",
       " 13.275778591854575,\n",
       " 13.289338595373493,\n",
       " 13.421196654906103,\n",
       " 13.447920596226867,\n",
       " 13.210120416180978,\n",
       " 13.416809497642124,\n",
       " 13.509258619779438,\n",
       " 13.374571434541199]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1['0.0']['0.0']['-0.008'].keys()\n",
    "d1['0.0']['0.0']['-0.008']['Distance_Median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f3152b2-b668-49eb-8cb9-117237149f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.652290260048257,\n",
       " 12.398381818493647,\n",
       " 12.375073517588884,\n",
       " 12.918176689022609,\n",
       " 12.70049485287421,\n",
       " 12.71346725624064,\n",
       " 12.83961146652684,\n",
       " 12.86517737039037,\n",
       " 12.637681864813135,\n",
       " 12.835414419410965,\n",
       " 12.923857412922327,\n",
       " 12.795006672377749]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2['0.0']['0.0']['-0.008'].keys()\n",
    "d2['0.0']['0.0']['-0.008']['Distance_Median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9767e8c-4bd5-45d7-aa9a-317bb947f965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.040645864746939 9.036581278272244 0.9997496400827489 0.899774676074474\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import normal\n",
    "r = normal(loc=10, scale=1, size=100)\n",
    "\n",
    "print(np.mean(r), np.mean(r*0.9), np.std(r), np.std(r*0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf02ecbc-8962-47e3-91a9-0ad96b23e1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.899774676074474"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9997496400827489*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "508ce343-d959-4597-bd02-19e031abaa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{} == {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3cb5e9-5665-4103-b892-4ae04bb8f251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
